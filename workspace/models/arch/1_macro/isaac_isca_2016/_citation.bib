@inproceedings{10.1109/ISCA.2016.12,
author = {Shafiee, Ali and Nag, Anirban and Muralimanohar, Naveen and Balasubramonian, Rajeev and Strachan, John Paul and Hu, Miao and Williams, R. Stanley and Srikumar, Vivek},
title = {ISAAC: a convolutional neural network accelerator with in-situ analog arithmetic in crossbars},
year = {2016},
isbn = {9781467389471},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISCA.2016.12},
doi = {10.1109/ISCA.2016.12},
abstract = {A number of recent efforts have attempted to design accelerators for popular machine learning algorithms, such as those involving convolutional and deep neural networks (CNNs and DNNs). These algorithms typically involve a large number of multiply-accumulate (dot-product) operations. A recent project, DaDianNao, adopts a near data processing approach, where a specialized neural functional unit performs all the digital arithmetic operations and receives input weights from adjacent eDRAM banks.This work explores an in-situ processing approach, where memristor crossbar arrays not only store input weights, but are also used to perform dot-product operations in an analog manner. While the use of crossbar memory as an analog dot-product engine is well known, no prior work has designed or characterized a full-fledged accelerator based on crossbars. In particular, our work makes the following contributions: (i) We design a pipelined architecture, with some crossbars dedicated for each neural network layer, and eDRAM buffers that aggregate data between pipeline stages. (ii) We define new data encoding techniques that are amenable to analog computations and that can reduce the high overheads of analog-to-digital conversion (ADC). (iii) We define the many supporting digital components required in an analog CNN accelerator and carry out a design space exploration to identify the best balance of memristor storage/compute, ADCs, and eDRAM storage on a chip. On a suite of CNN and DNN workloads, the proposed ISAAC architecture yields improvements of 14.8\texttimes{}, 5.5\texttimes{}, and 7.5\texttimes{} in throughput, energy, and computational density (respectively), relative to the state-of-the-art DaDianNao architecture.},
booktitle = {Proceedings of the 43rd International Symposium on Computer Architecture},
pages = {14â€“26},
numpages = {13},
keywords = {CNN, DNN, accelerator, analog, memristor, neural},
location = {Seoul, Republic of Korea},
series = {ISCA '16}
}

