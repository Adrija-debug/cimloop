@inproceedings{cimloop,
  author={Andrulis, Tanner and Emer, Joel S. and Sze, Vivienne},
  booktitle={2024 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={{CiMLoop}: A Flexible, Accurate, and Fast Compute-In-Memory Modeling Tool}, 
  year={2024},
  volume={},
  number={},
  pages={},
  keywords={Compute-In-Memory;Processing-In-Memory;Analog;Deep Neural Networks;Systems;Hardware;Modeling;Open-Source},
  doi={}
}
@inproceedings{timeloop,
  title={Timeloop: A systematic approach to dnn accelerator evaluation},
  author={Parashar, Angshuman and Raina, Priyanka and Shao, Yakun Sophia and
  Chen, Yu-Hsin and Ying, Victor A and Mukkara, Anurag and Venkatesan,
  Rangharajan and Khailany, Brucek and Keckler, Stephen W and Emer, Joel},
  booktitle={2019 IEEE international symposium on performance analysis of
  systems and software (ISPASS)}, pages={304--315}, year={2019},
  organization={IEEE}
}
@inproceedings{accelergy,
  title={Accelergy: An architecture-level energy estimation methodology for accelerator designs},
  author={Wu, Yannan Nellie and Emer, Joel S and Sze, Vivienne},
  booktitle={2019 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)},
  pages={1--8},
  year={2019},
  organization={IEEE}
}
@inproceedings {ruby,
  author = {M. Horeni and P. Taheri and P. Tsai and A. Parashar and J. Emer and S. Joshi},
  booktitle = {2022 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)},
  title = {Ruby: Improving Hardware Efficiency for Tensor Algebra Accelerators Through Imperfect Factorization},
  year = {2022},
  volume = {},
  issn = {},
  pages = {254-266},
  keywords = {deep learning;tensors;codes;neural networks;computer architecture;parallel processing;hardware},
  doi = {10.1109/ISPASS55109.2022.00039},
  url = {https://doi.ieeecomputersociety.org/10.1109/ISPASS55109.2022.00039},
  publisher = {IEEE Computer Society},
  address = {Los Alamitos, CA, USA},
  month = {may}
}

# If you use CiMloop for photonic accelerator modeling, please cite the following paper:
@inproceedings {cimloop_photonics,
  author={Andrulis, Tanner and Chaudhry, Gohar Irfan and Suriyakumar, Vinith M. and Emer, Joel S. and Sze, Vivienne},
  booktitle={2024 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)}, 
  title={Architecture-Level Modeling of Photonic Deep
Neural Network Accelerators}, 
  year={2024},
  volume={},
  number={},
  pages={},
  keywords={photonics, optical computing, photonic computing, compute-in-memory, modeling, accelerator},
  doi={}
}

# If you use the built-in ADC model, please cite the following paper:
@misc{andrulis2024modeling,
      title={Modeling Analog-Digital-Converter Energy and Area for Compute-In-Memory Accelerator Design}, 
      author={Tanner Andrulis and Ruicong Chen and Hae-Seung Lee and Joel S. Emer and Vivienne Sze},
      year={2024},
      eprint={2404.06553},
      archivePrefix={arXiv},
      primaryClass={cs.AR}
}

# If you use any of the NeuroSim components (row drivers, column drivers, memory
cells), please cite the following paper:
@ARTICLE{DNN+NeuroSim,  
  author={Peng, Xiaochen and Huang, Shanshi and Jiang, Hongwu and Lu, Anni and Yu, Shimeng}, 
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={{DNN+NeuroSim} {V2.0}: An End-to-End Benchmarking Framework for Compute-in-Memory Accelerators for On-Chip Training},   year={2021}, volume={40},  number={11},
  pages={2306-2319},  doi={10.1109/TCAD.2020.3043731}
}
